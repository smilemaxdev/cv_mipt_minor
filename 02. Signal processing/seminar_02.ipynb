{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Семинар №2. Обработка сигналов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:39.881944Z",
     "start_time": "2020-09-14T17:47:39.873975Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt,exp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Преобразование Фурье**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте поговорим немного о частотном пространстве перед тем, как углубимся в детали. Термин частота происходит из физики, как некоторое изменение во времени, описание характеристики некоторого периодического движения или поведения. Например, термин частота в компьютерном зрении обычно связан с вариацией яркости или цвета вдоль изображения, то есть является функцией пространственных координат, а не времени. Некоторые книги даже называют ее пространственной частотой (spatial frequency).\n",
    "\n",
    "Например, если изображение, представленное в частотном пространстве, имеет высокие частоты, то это означает, что на нем присутствуют острые углы или детали. Давайте посмотрим на рисунки ниже, слева изображено исходное изображение, а справа — частотный график этой картинки.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:44:14.566416Z",
     "start_time": "2020-09-14T17:44:14.562388Z"
    }
   },
   "outputs": [],
   "source": [
    "def centered_spectrum(image):\n",
    "    spectrum = np.fft.fft2(image)\n",
    "    spectrum = np.fft.fftshift(spectrum)\n",
    "    return spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:46:44.097139Z",
     "start_time": "2020-09-14T17:46:42.967205Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    image = cv2.imread(f'img/test_freq{i}.png', 0)\n",
    "    spectrum = centered_spectrum(image)\n",
    "\n",
    "    plt.figure(figsize=(6.4*2, 4.8*2), constrained_layout=False)\n",
    "    plt.subplot(121), plt.imshow(image, \"gray\"), plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(122), plt.imshow(np.log(1+np.abs(spectrum)), \"gray\"), plt.title(\"Spectrum\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T19:22:46.340264Z",
     "start_time": "2020-09-13T19:22:46.333751Z"
    }
   },
   "source": [
    "Если у вас возникли проблемы с пониманием частотных графиков: члены ряда с низкой частотой находятся в центре квадрата, а члены с высокой частотой — на краях. Представьте невидимые оси с началом координат в центре квадрата. Теперь, частотное пространство на первой сверху слева картинке состоит как из высоких частот, так и из низких, поэтому исходное изображение имеет резкие границы. Однако второе изображение более нечеткое, и, конечно, график частоты для него имеет меньше высокочастотных членов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частотная область вносит существенные преимущества в обработку изображений (image processing). Она позволяет делать крупные операции фильтрации гораздо быстрее. Так как информация об изображении хранится в частотах, то это позволяет иногда отделить сигнал от шума, а также осуществлять различные вычисления, которые были бы очень трудоемкими в пространственной области. Кроме того Fourier Transform позволяет легко осуществлять переход из пространственной области в частотную и наоборот.\n",
    "\n",
    "Например, допустим, у нас есть изображение с некоторым периодичным шумом, который мы хотели бы устранить. (Представьте себе отсканированную страницу с сероватыми полосами.) Если перевести данные изображения в частотное пространство, то любой периодический шум в исходной картинке будет отображаться как яркие пятна на диаграмме в частотном пространстве. Если мы устраним эти точки и применим inverse Fourier Transform, чтобы получить исходное изображение, мы сможем удалить большую часть шума и тем самым улучшить видимость изображения.\n",
    "\n",
    "Начальное изображение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:00.592719Z",
     "start_time": "2020-09-14T17:46:59.913627Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "img_c1 = cv2.imread(\"img/lena_noise_image.png\", 0)\n",
    "img_c2 = np.fft.fft2(img_c1)\n",
    "img_c3 = np.fft.fftshift(img_c2)\n",
    "img_c4 = np.fft.ifftshift(img_c3)\n",
    "img_c5 = np.fft.ifft2(img_c4)\n",
    "\n",
    "plt.subplot(151), plt.imshow(img_c1, \"gray\"), plt.title(\"Original Image\")\n",
    "plt.subplot(152), plt.imshow(np.log(1+np.abs(img_c2)), \"gray\"), plt.title(\"Spectrum\")\n",
    "plt.subplot(153), plt.imshow(np.log(1+np.abs(img_c3)), \"gray\"), plt.title(\"Centered Spectrum\")\n",
    "plt.subplot(154), plt.imshow(np.log(1+np.abs(img_c4)), \"gray\"), plt.title(\"Decentralized\")\n",
    "plt.subplot(155), plt.imshow(np.abs(img_c5), \"gray\"), plt.title(\"Processed Image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомним уравнения\n",
    "\n",
    "Пусть $f(x)$ — непрерывная функция вещественной переменной  $x$. Преобразование Фурье (Fourier Transform) функции  $f(x)$  определяется уравнением:\n",
    "\n",
    "$F(u)=\\int^{-\\infty}_{\\infty}f(x)e^{-i2\\pi ux}\\,dx$\n",
    "\n",
    "где  $i=\\sqrt{-1}$  и  u  часто называется частотной переменной. Суммирование синусов и косинусов может быть не таким очевидным на первый взгляд, но, применяя уравнение Эйлера, получаем:\n",
    "\n",
    "$F(u)=\\int^{-\\infty}_{\\infty}f(x)(cos 2\\pi ux -i sin 2\\pi ux)\\,dx$\n",
    "\n",
    "По данному $F(u)$ мы можем вернуться назад и получить $f(x)$, используя обратное преобразование Фурье (inverse Fourier Transform):\n",
    "\n",
    "$f(x)=\\int^{-\\infty}_{\\infty}F(u)e^{i2\\pi ux}\\,dx$\n",
    "\n",
    "Обратите внимание, что единственная разница между прямым и обратным преобразованием Фурье это знак, который легко позволяет перемещаться назад и вперед между пространственным и частотным областями; это одна из характеристик, которые делают преобразование Фурье полезным.\n",
    "\n",
    "Некоторые могут спросить, что же такое  $F(u)$.  $F(u)$ это как раз данные в частотном пространстве, о котором мы говорили в первой секции. Даже если мы начинаем с вещественной функции $f(x)$  в пространственной области, мы обычно заканчиваем комплексными значениями  $F(u)$. Это происходит потому, что вещественное число, умноженное на комплексное, дает комплексное число.\n",
    "\n",
    "Итак, $f(x)e^{i2\\pi ux}$  — комплексное, поэтому сумма этих членов должна также дать комплексное число, то есть  $F(u)$. Поэтому,\n",
    "\n",
    "$F(u)=R(u)+iI(u)$\n",
    "\n",
    "где $R(u)$ является вещественной компонентой (члены, не содержащие  $i$) и  $I(u)$ есть комплексная компонента (члены, содержащие $i$); $(u)$ написано, чтобы напомнить, что члены являются функциями от $u$. Как любые другие комплексные числа, мы также можем записать их в полярной форме, дающей:\n",
    "\n",
    "$F(u)=r(sin \\theta + i cos \\theta)=re^{i\\theta}$\n",
    "\n",
    "В большинстве учебников эта форма Fourier Transform записывается в виде:\n",
    "\n",
    "$F(u)=\\left|F(u)\\right|e^{i\\theta(u)}$\n",
    "\n",
    "но это по сути одно и то же.\n",
    "\n",
    "Существует несколько часто используемых слов, когда речь идет о преобразовании Фурье.  Модуль  $\\left|F(u)\\right|$ называется спектром Фурье (Fourier spectrum) функции  $f(x)$  и  $\\theta(u)$  это фазовый угол (phase angle). Квадрат спектра,  $\\left|F(u)\\right|^2=R^2(u)+I^2(u)$  часто обозначается как  $P(u)$  и называется спектром мощности (power spectrum) функции  $f(x)$. Термин плотность спектра (spectral density) также широко используется для обозначения спектра мощности. Спектр Фурье часто строится от $u$.\n",
    "\n",
    "<td> <img src=\"img/fourier_plot.png\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "\n",
    "На картинке изображена простая функция и ее спектр Фурье.\n",
    "\n",
    "Заметьте, что сами $F(u)$  трудно построить от  $u$  в 2-D пространстве, так как они комплексные числа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дискретное преобразование Фурье\n",
    "\n",
    "Учитываются  $N$  дискретных значений  $f(x)$, отобранных с единым шагом,\n",
    "\n",
    "$F(u)=\\frac{1}{N}\\sum_{x=0}^{N-1}f(x)e^{-i2\\pi ux/N}$\n",
    "\n",
    "для  $u=0,1,2,...,N-1,$  и\n",
    "\n",
    "$f(x)=\\sum_{u=0}^{N-1}F(u)e^{i2\\pi ux/N}$\n",
    "\n",
    "для  $x=0,1,2,...,N-1$.\n",
    "\n",
    "Обратите внимание, что интеграл заменяется на суммирование, которое является простым «for loop» при программировании. Для тех, кому любопытно, расчет внутри  $\\sum$  это произведение  $f(x)=R+iI$  на  $e^{i2\\pi ux/N}=cos(p)-isin(p)$  где  $p=2\\pi ux/N$:\n",
    "\n",
    "$f(x)=e^{i2\\pi ux/N}=(R+iI)*(cos(p)-isin(p))$\n",
    "\n",
    "$=Rcos(p)-Risin(p)+Iicos(p)-Ii^2sin(p)$\n",
    "\n",
    "$=Rcos(p)-Risin(p)+Iicos(p)+Isin(p)$\n",
    "\n",
    "$=(Rcos(p)+Isin(p))+i(Icos(p)-Rsin(p)),$\n",
    "\n",
    "где  $R$,  $I$  — вещественные числа, и  $I=0$, когда $f(x)$  — вещественное число."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтры \n",
    "\n",
    "Разделяют понятия о **низких** и **высоких** частотах.\n",
    "\n",
    "**Фильтр низких частот** - это фильтр, который пропускает только низкие частоты. Низкие частоты в изображениях означают медленно изменяющиеся значения пикселей. Например, гладкая область со слегка изменяющимся цветом на изображении, например, центр новой пустой белой бумаги, считается низкочастотным содержимым.\n",
    "Поскольку выходной фильтр низких частот пропускает только низкие частоты, содержимое высоких частот, такое как шумы, блокируется, что делает обработанное изображение менее шумным. Поэтому низкочастотный фильтр широко используется для удаления шумов в изображениях.\n",
    "\n",
    "\n",
    "**Фильтр высоких частот**, напротив, является фильтром, который пропускает только высокие частоты. Высокие частоты в изображениях означают резко изменяющиеся значения пикселей. Например, области краев изображения с огромным изменением цвета, такие как края между двумя перекрывающимися белой и черной бумагой, считаются высокочастотным содержимым.\n",
    "Выходной сигнал фильтра высоких частот захватывает края в изображении, которые могут быть использованы для повышения резкости исходного изображения с правильным расчетом перекрытия. Это повышает резкость исходного изображения, делая края более четкими."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Filter\n",
    "\n",
    "Идея, которая лежит в основе идеального фильтра, очень проста: При значении радиуса D₀ в качестве порогового, фильтр нижних частот имеет H(u, v) равное 1 под пороговым значением, а H(u, v) равное 0 при превышении порогового значения.\n",
    "\n",
    "<td> <img src=\"img/idealLP.png\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>\n",
    "\n",
    "<td> <img src=\"img/idealHP.png\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:03.790905Z",
     "start_time": "2020-09-14T17:47:03.782924Z"
    }
   },
   "outputs": [],
   "source": [
    "def distance(point1,point2):\n",
    "    return sqrt((point1[0]-point2[0])**2 + (point1[1]-point2[1])**2)\n",
    "\n",
    "def idealFilterLP(D0,imgShape):\n",
    "    base = np.zeros(imgShape[:2])\n",
    "    rows, cols = imgShape[:2]\n",
    "    center = (rows/2,cols/2)\n",
    "    for x in range(cols):\n",
    "        for y in range(rows):\n",
    "            if distance((y,x),center) < D0:\n",
    "                base[y,x] = 1\n",
    "    return base\n",
    "\n",
    "def idealFilterHP(D0,imgShape):\n",
    "    base = np.ones(imgShape[:2])\n",
    "    rows, cols = imgShape[:2]\n",
    "    center = (rows/2,cols/2)\n",
    "    for x in range(cols):\n",
    "        for y in range(rows):\n",
    "            if distance((y,x),center) < D0:\n",
    "                base[y,x] = 0\n",
    "    return base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:05.768207Z",
     "start_time": "2020-09-14T17:47:04.977062Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*6, 4.8*6), constrained_layout=False)\n",
    "\n",
    "img = cv2.imread(\"img/lena_noise_image.png\", 0)\n",
    "plt.subplot(161), plt.imshow(img, \"gray\"), plt.title(\"Original Image\")\n",
    "\n",
    "original = np.fft.fft2(img)\n",
    "plt.subplot(162), plt.imshow(np.log(1+np.abs(original)), \"gray\"), plt.title(\"Spectrum\")\n",
    "\n",
    "center = np.fft.fftshift(original)\n",
    "plt.subplot(163), plt.imshow(np.log(1+np.abs(center)), \"gray\"), plt.title(\"Centered Spectrum\")\n",
    "\n",
    "LowPassCenter = center * idealFilterLP(50,img.shape)\n",
    "plt.subplot(164), plt.imshow(np.log(1+np.abs(LowPassCenter)), \"gray\"), plt.title(\"Centered Spectrum multiply Low Pass Filter\")\n",
    "\n",
    "LowPass = np.fft.ifftshift(LowPassCenter)\n",
    "plt.subplot(165), plt.imshow(np.log(1+np.abs(LowPass)), \"gray\"), plt.title(\"Decentralize\")\n",
    "\n",
    "inverse_LowPass = np.fft.ifft2(LowPass)\n",
    "plt.subplot(166), plt.imshow(np.abs(inverse_LowPass), \"gray\"), plt.title(\"Processed Image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:07.114384Z",
     "start_time": "2020-09-14T17:47:06.408942Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/lena_noise_image.png\", 0)\n",
    "original = np.fft.fft2(img)\n",
    "center = np.fft.fftshift(original)\n",
    "\n",
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "plt.subplot(161), plt.imshow(np.log(1+np.abs(center)), \"gray\"), plt.title(\"Spectrum\")\n",
    "\n",
    "HighPass = idealFilterHP(50,img.shape)\n",
    "plt.subplot(162), plt.imshow(np.abs(HighPass), \"gray\"), plt.title(\"High Pass Filter\")\n",
    "\n",
    "HighPassCenter = center * idealFilterHP(50,img.shape)\n",
    "plt.subplot(163), plt.imshow(np.log(1+np.abs(HighPassCenter)), \"gray\"), plt.title(\"Centered Spectrum multiply High Pass Filter\")\n",
    "\n",
    "HighPass = np.fft.ifftshift(HighPassCenter)\n",
    "plt.subplot(164), plt.imshow(np.log(1+np.abs(HighPass)), \"gray\"), plt.title(\"Decentralize\")\n",
    "\n",
    "inverse_HighPass = np.fft.ifft2(HighPass)\n",
    "plt.subplot(165), plt.imshow(np.abs(inverse_HighPass), \"gray\"), plt.title(\"Processed Image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Btterworth Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от идеального фильтра, фильтр Баттерворта не имеет резких разрывов, что дает четкое разделение между проходной и отфильтрованной частотами. Фильтр Баттерворта вводит в функцию новый параметр $n$. При работе с $n$ он влияет на чистоту среза между переданной и отфильтрованной частотами.\n",
    "\n",
    "<td> <img src=\"img/butterLP.png\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>\n",
    "\n",
    "<td> <img src=\"img/butterHP.png\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:07.828505Z",
     "start_time": "2020-09-14T17:47:07.818450Z"
    }
   },
   "outputs": [],
   "source": [
    "def butterworthLP(D0,imgShape,n):\n",
    "    base = np.zeros(imgShape[:2])\n",
    "    rows, cols = imgShape[:2]\n",
    "    center = (rows/2,cols/2)\n",
    "    for x in range(cols):\n",
    "        for y in range(rows):\n",
    "            base[y,x] = 1/(1+(distance((y,x),center)/D0)**(2*n))\n",
    "    return base\n",
    "\n",
    "def butterworthHP(D0,imgShape,n):\n",
    "    base = np.zeros(imgShape[:2])\n",
    "    rows, cols = imgShape[:2]\n",
    "    center = (rows/2,cols/2)\n",
    "    for x in range(cols):\n",
    "        for y in range(rows):\n",
    "            base[y,x] = 1-1/(1+(distance((y,x),center)/D0)**(2*n))\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:09.055907Z",
     "start_time": "2020-09-14T17:47:08.627031Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "LowPass = idealFilterLP(50,img.shape)\n",
    "plt.subplot(131), plt.imshow(LowPass, \"gray\"), plt.title(\"Ideal Low Pass Filter\")\n",
    "\n",
    "HighPass = idealFilterHP(50,img.shape)\n",
    "plt.subplot(132), plt.imshow(HighPass, \"gray\"), plt.title(\"Ideal High Pass Filter\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:10.008432Z",
     "start_time": "2020-09-14T17:47:09.503547Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "LowPass = butterworthLP(50,img.shape,20)\n",
    "plt.subplot(131), plt.imshow(LowPass, \"gray\"), plt.title(\"Butterworth Low Pass Filter (n=20)\")\n",
    "\n",
    "HighPass = butterworthHP(50,img.shape,20)\n",
    "plt.subplot(132), plt.imshow(HighPass, \"gray\"), plt.title(\"Butterworth High Pass Filter (n=20)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:10.889610Z",
     "start_time": "2020-09-14T17:47:10.400454Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "LowPass = butterworthLP(50,img.shape,3)\n",
    "plt.subplot(131), plt.imshow(LowPass, \"gray\"), plt.title(\"Butterworth Low Pass Filter (n=3)\")\n",
    "\n",
    "HighPass = butterworthHP(50,img.shape,3)\n",
    "plt.subplot(132), plt.imshow(HighPass, \"gray\"), plt.title(\"Butterworth High Pass Filter (n=3)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гауссовский фильтр - более плавная версия, чем Баттерворт. Отсечение между переданной и отфильтрованной частотами очень размыто, что приводит к более гладкой обработке изображений.\n",
    "\n",
    "<td> <img src=\"img/gaussLP.png\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>\n",
    "\n",
    "<td> <img src=\"img/gaussHP.png\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:11.917911Z",
     "start_time": "2020-09-14T17:47:11.910927Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussianLP(D0,imgShape):\n",
    "    base = np.zeros(imgShape[:2])\n",
    "    rows, cols = imgShape[:2]\n",
    "    center = (rows/2,cols/2)\n",
    "    for x in range(cols):\n",
    "        for y in range(rows):\n",
    "            base[y,x] = exp(((-distance((y,x),center)**2)/(2*(D0**2))))\n",
    "    return base\n",
    "\n",
    "def gaussianHP(D0,imgShape):\n",
    "    base = np.zeros(imgShape[:2])\n",
    "    rows, cols = imgShape[:2]\n",
    "    center = (rows/2,cols/2)\n",
    "    for x in range(cols):\n",
    "        for y in range(rows):\n",
    "            base[y,x] = 1 - exp(((-distance((y,x),center)**2)/(2*(D0**2))))\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:13.116004Z",
     "start_time": "2020-09-14T17:47:12.537564Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "LowPass = gaussianLP(50,img.shape)\n",
    "plt.subplot(131), plt.imshow(LowPass, \"gray\"), plt.title(\"Gaussian Low Pass Filter\")\n",
    "\n",
    "HighPass = gaussianHP(50,img.shape)\n",
    "plt.subplot(132), plt.imshow(HighPass, \"gray\"), plt.title(\"Gaussian High Pass Filter\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Только фильтры\n",
    "\n",
    "Посмотрим сразу на все фильтры, рассмотренные ранее. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:15.446054Z",
     "start_time": "2020-09-14T17:47:13.942005Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "IdealLP = idealFilterLP(50,img.shape)\n",
    "plt.subplot(131), plt.imshow(IdealLP, \"gray\"), plt.title(\"Ideal Low Pass Filter\")\n",
    "\n",
    "ButterLP = butterworthLP(50,img.shape,10)\n",
    "plt.subplot(132), plt.imshow(ButterLP, \"gray\"), plt.title(\"Butterworth Low Pass Filter (n=10)\")\n",
    "\n",
    "GaussianLP = gaussianLP(50,img.shape)\n",
    "plt.subplot(133), plt.imshow(GaussianLP, \"gray\"), plt.title(\"Gaussian Low Pass Filter\")\n",
    "\n",
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "IdealHP = idealFilterHP(50,img.shape)\n",
    "plt.subplot(231), plt.imshow(IdealHP, \"gray\"), plt.title(\"Ideal High Pass Filter\")\n",
    "\n",
    "ButterHP = butterworthHP(50,img.shape,10)\n",
    "plt.subplot(232), plt.imshow(ButterHP, \"gray\"), plt.title(\"Butterworth High Pass Filter (n=10)\")\n",
    "\n",
    "GaussianHP = gaussianHP(50,img.shape)\n",
    "plt.subplot(233), plt.imshow(GaussianHP, \"gray\"), plt.title(\"Gaussian High Pass Filter\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Фильтры на изображении\n",
    "\n",
    "Теперь применим каждый из этих фильтров к исходному изображению и посмотрим на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:16.802155Z",
     "start_time": "2020-09-14T17:47:15.935614Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/lena_noise_image.png\", 0)\n",
    "original = np.fft.fft2(img)\n",
    "center = np.fft.fftshift(original)\n",
    "\n",
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "LowPassCenter = center * idealFilterLP(50,img.shape)\n",
    "LowPass = np.fft.ifftshift(LowPassCenter)\n",
    "inverse_LowPass = np.fft.ifft2(LowPass)\n",
    "plt.subplot(131), plt.imshow(np.abs(inverse_LowPass), \"gray\"), plt.title(\"Ideal Low Pass\")\n",
    "\n",
    "LowPassCenter = center * butterworthLP(50,img.shape,10)\n",
    "LowPass = np.fft.ifftshift(LowPassCenter)\n",
    "inverse_LowPass = np.fft.ifft2(LowPass)\n",
    "plt.subplot(132), plt.imshow(np.abs(inverse_LowPass), \"gray\"), plt.title(\"Butterworth Low Pass (n=10)\")\n",
    "\n",
    "LowPassCenter = center * gaussianLP(50,img.shape)\n",
    "LowPass = np.fft.ifftshift(LowPassCenter)\n",
    "inverse_LowPass = np.fft.ifft2(LowPass)\n",
    "plt.subplot(133), plt.imshow(np.abs(inverse_LowPass), \"gray\"), plt.title(\"Gaussian Low Pass\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:18.124003Z",
     "start_time": "2020-09-14T17:47:17.207174Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/lena_noise_image.png\", 0)\n",
    "original = np.fft.fft2(img)\n",
    "center = np.fft.fftshift(original)\n",
    "\n",
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "HighPassCenter = center * idealFilterHP(50,img.shape)\n",
    "HighPass = np.fft.ifftshift(HighPassCenter)\n",
    "inverse_HighPass = np.fft.ifft2(HighPass)\n",
    "plt.subplot(131), plt.imshow(np.abs(inverse_HighPass), \"gray\"), plt.title(\"Ideal High Pass\")\n",
    "\n",
    "HighPassCenter = center * butterworthHP(50,img.shape,10)\n",
    "HighPass = np.fft.ifftshift(HighPassCenter)\n",
    "inverse_HighPass = np.fft.ifft2(HighPass)\n",
    "plt.subplot(132), plt.imshow(np.abs(inverse_HighPass), \"gray\"), plt.title(\"Butterworth High Pass (n=10)\")\n",
    "\n",
    "HighPassCenter = center * gaussianHP(50,img.shape)\n",
    "HighPass = np.fft.ifftshift(HighPassCenter)\n",
    "inverse_HighPass = np.fft.ifft2(HighPass)\n",
    "plt.subplot(133), plt.imshow(np.abs(inverse_HighPass), \"gray\"), plt.title(\"Gaussian High Pass\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:24.250290Z",
     "start_time": "2020-09-14T17:47:23.345537Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/lena_noise_image.png\", 0)\n",
    "original = np.fft.fft2(img)\n",
    "center = np.fft.fftshift(original)\n",
    "\n",
    "plt.figure(figsize=(6.4*5, 4.8*5), constrained_layout=False)\n",
    "\n",
    "plt.subplot(131), plt.imshow(img, \"gray\"), plt.title(\"Original Image\")\n",
    "\n",
    "LowPassCenter = center * gaussianLP(50,img.shape)\n",
    "LowPass = np.fft.ifftshift(LowPassCenter)\n",
    "inverse_LowPass = np.fft.ifft2(LowPass)\n",
    "plt.subplot(132), plt.imshow(np.abs(inverse_LowPass), \"gray\"), plt.title(\"Gaussian Low Pass\")\n",
    "\n",
    "HighPassCenter = center * gaussianHP(50,img.shape)\n",
    "HighPass = np.fft.ifftshift(HighPassCenter)\n",
    "inverse_HighPass = np.fft.ifft2(HighPass)\n",
    "plt.subplot(133), plt.imshow(np.abs(inverse_HighPass), \"gray\"), plt.title(\"Gaussian High Pass\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Свертки (теория)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основы сверток\n",
    "**Свертки** $-$ это метод общей обработки сигналов. Люди, изучающие электронику, скажут вам о почти бесконечных бессонных ночах, которые были потрачены на их постижение. На эту тему написано множество книг. Но для компьютерного зрения мы просто разберемся с некоторыми простыми вещами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение\n",
    "Во-первых, давайте посмотрим на математическое определение свертки в дискретной области времени. Позже мы пройдемся по тому, что говорит нам это уравнение.\n",
    "${\\begin{align}y[n]&=x[n]*h[n]=\\sum_{k=-\\infty}^\\infty x[k]\\cdot h[n-k]\\end{align},}$\n",
    "\n",
    "где:\n",
    "* **x[n]** $-$ входой сигнал;\n",
    "* **h[n]** $-$ импульсный отклик; \n",
    "* **y[n]** $-$ выходной сигнал;\n",
    "* **$*$** $-$ обозначает свертку. \n",
    "\n",
    "Обратите внимание, что мы умножаем слагаемые $x[k]$ на смещенные по времени $h[n]$ и складываем их.\n",
    "Краеугольный камень понимания свертки лежит в основе импульсного отклика и импульсного разложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разложение импульсной функции\n",
    "\n",
    "Чтобы понять смысл свертки, мы собираемся начать с концепции разложения сигналов. Входной сигнал разлагается на простые аддитивные компоненты, и системный отклик входного сигнала приводит к сложению выходных данных этих компонентов, прошедших через систему.\n",
    "\n",
    "В общем, сигнал может быть разложен как взвешенная сумма базовых сигналов. Например, в рядах Фурье любой периодический сигнал (даже прямоугольный импульсный сигнал) может быть представлен суммой функций синуса и косинуса. Но здесь мы используем импульсные (дельта) функции для базовых сигналов, а не синус и косинус.\n",
    "\n",
    "Изучим следующий пример того, как сигнал разлагается на набор импульсных (дельта) функций:\n",
    "<img src=\"img/conv_img01.png\" alt=\"Drawing\" style=\"width: 200px;\"/> \n",
    "\n",
    "Импульсная функция выглядит так: ${\\delta(n)={\\begin{cases}1, n=0\\\\ 0, n\\ne0 \\end{cases}}}$.  Тогда для данного примера $x[0]$ можно записать в виде ${x[0] = x[0] \\cdot \\delta[n-0] = 2 \\cdot \\delta[n-0]}$. Тогда $x[1]$ будет равен ${x[1] = x[1] \\cdot \\delta[n-1] = 3 \\cdot \\delta[n-1]}$, потому что ${\\delta[n-1]}$ равна $1$ при $n = 1$ и ноль в других случаях. Таким же образом мы можем записать ${x[2] = x[2] \\cdot \\delta[n-2] = 1 \\cdot \\delta[n-2]}$, сдвинув ${\\delta[n]}$ на 2. Следовательно, сигнал $x[n]$ может быть представлен добавлением $3$ сдвинутых и масштабированных импульсных функций.\n",
    "\n",
    "В общем, сигнал может быть записан как сумма масштабированных и сдвинутых дельта-функций:\n",
    "${\\begin{align}x[n]=\\sum_{k=0}^2 x[k]\\cdot\\delta[n-k]=x[0]\\cdot\\delta[n-0]+x[1]\\cdot\\delta[n-1]+x[2]\\cdot\\delta[n-2]\\end{align}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импульсивный отклик\n",
    "**Импульсный отклик** $-$ это выход системы, являющийся результатом импульсной функции в качестве входа.\n",
    "Именно это обозначается за $h[n]$. Все волшебство именно тут. Для вас это перестанет быть магией на 2-3 курсе инстиута. \n",
    "\n",
    "Существует огромное множество преобразования для импульсного отклика. Мы рассмотрим только конечные формулы без понимания того, как работает математика.\n",
    "\n",
    "<td> <img src=\"img/conv_img02.png\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Свертка в 2D\n",
    "2D свертка является просто продолжением предыдущей 1D свертки путем свертки как горизонтального, так и вертикального направлений в двухмерной пространственной области. Свертка часто используется для обработки изображений, таких как сглаживание, повышение резкости и обнаружение краев изображений.\n",
    "\n",
    "Импульсная (дельта) функция также находится в двумерном пространстве, поэтому ${\\delta[m,n]={\\begin{cases}1,\\ m=n=0\\\\0,\\ m\\ne0,n\\ne0\\end{cases}}}$. Импульсный отклик в 2D обычно называют **«ядром»** или **«фильтром»** в обработке изображений.\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"img/conv2d_delta.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "    <td> <img src=\"img/conv_img10.png\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Кроме того, выходные данные линейной и инвариантной по времени системы могут быть записаны путем свертки входного сигнала $x[m,n]$ и импульсной характеристики $h[m,n]$:\n",
    "${\\begin{align}y[m,n]=x[m,n]*h[m,n]=\\sum_{j=-\\infty}^\\infty \\sum_{i=-\\infty}^\\infty x[i,j]\\cdot h[m-i,n-j]\\end{align}}$\n",
    "\n",
    "Изучим пример, чтобы уточнить, как работает свертка в **2D**-пространстве.\n",
    "Допустим, что размер импульсного отклика (ядра) составляет $3\\times3$, а его значения **a, b, c, d, ...**\n",
    "\n",
    "Обратите внимание, что начало координат $(0,0)$ находится в центре ядра.\n",
    "\n",
    "Давайте выберем простейший пример и вычислим свертку, например, результат в $(1,1)$:\n",
    "<img src=\"img/conv_img11.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "${\\begin{align}\n",
    "y[1,1] & = \\sum_{j=0}^2 \\sum_{i=0}^2 x[i,j] \\cdot h[1-i,1-j]  \\\\ &\n",
    "= x[0,0] \\cdot h[1,1] + x[1,0] \\cdot h[0,1] + x[2,0] \\cdot h[-1,1] \\\\ &\n",
    "+ x[0,1] \\cdot h[1,0] + x[1,1] \\cdot h[0,0] + x[2,1] \\cdot h[-1,0] \\\\ &\n",
    "+ x[0,2] \\cdot h[1,-1] + x[1,2] \\cdot h[0,-1] + x[2,2] \\cdot h[-1,-1]\n",
    "\\end{align}}$\n",
    "\n",
    "Рассмотрим более конкртеный пример с двумерной сверткой. Предположим, у нас есть входные матрицы $3\\times3$ и ядра $3\\times3$ следующим образом:\n",
    "\n",
    "Input | Kernel | Output\n",
    "-|-|-\n",
    "<img src=\"img/conv_img15.png\" alt=\"Drawing\" style=\"width: 200px;\"/> | <img src=\"img/conv_img16.png\" alt=\"Drawing\" style=\"width: 200px;\"/> | <img src=\"img/conv_img17.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "Выходной сигнал в точке $(1,1)$ для этого примера будет:\n",
    "${\\begin{align}\n",
    "\\ y[1,1] & = \\sum_{j=0}^2 \\sum_{i=0}^2 x[i,j] \\cdot h[1-i,1-j]  \\\\ &\n",
    "\\ = x[0,0] \\cdot h[1,1] + x[1,0] \\cdot h[0,1] + x[2,0] \\cdot h[-1,1] \\\\ &\n",
    "\\ + x[0,1] \\cdot h[1,0] + x[1,1] \\cdot h[0,0] + x[2,1] \\cdot h[-1,0] \\\\ &\n",
    "\\ + x[0,2] \\cdot h[1,-1] + x[1,2] \\cdot h[0,-1] + x[2,2] \\cdot h[-1,-1] \\\\&\n",
    "\\ = 1 \\cdot 1 + 2 \\cdot 2 + 3 \\cdot 1 \\\\ &\n",
    "\\ + 4 \\cdot 0 + 5 \\cdot 0 + 6 \\cdot 0 \\\\ &\n",
    "\\ + 7 \\cdot (-1) + 8 \\cdot (-2) + 9 \\cdot (-1) \\\\ &\n",
    "\\ = -24 \\\\\n",
    "\\end{align}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution animations\n",
    "\n",
    "_N.B.: Blue maps are inputs, and cyan maps are outputs._\n",
    "\n",
    "<table style=\"width:100%; table-layout:fixed;\">\n",
    "  <tr>\n",
    "    <td><img width=\"150px\" src=\"img/gif/no_padding_no_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/arbitrary_padding_no_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/same_padding_no_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/full_padding_no_strides.gif\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>No padding, no strides</td>\n",
    "    <td>Arbitrary padding, no strides</td>\n",
    "    <td>Half padding, no strides</td>\n",
    "    <td>Full padding, no strides</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img width=\"150px\" src=\"img/gif/no_padding_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/padding_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/padding_strides_odd.gif\"></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>No padding, strides</td>\n",
    "    <td>Padding, strides</td>\n",
    "    <td>Padding, strides (odd)</td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "## Transposed convolution animations\n",
    "\n",
    "_N.B.: Blue maps are inputs, and cyan maps are outputs._\n",
    "\n",
    "<table style=\"width:100%; table-layout:fixed;\">\n",
    "  <tr>\n",
    "    <td><img width=\"150px\" src=\"img/gif/no_padding_no_strides_transposed.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/arbitrary_padding_no_strides_transposed.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/same_padding_no_strides_transposed.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/full_padding_no_strides_transposed.gif\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>No padding, no strides, transposed</td>\n",
    "    <td>Arbitrary padding, no strides, transposed</td>\n",
    "    <td>Half padding, no strides, transposed</td>\n",
    "    <td>Full padding, no strides, transposed</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img width=\"150px\" src=\"img/gif/no_padding_strides_transposed.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/padding_strides_transposed.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"img/gif/padding_strides_odd_transposed.gif\"></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>No padding, strides, transposed</td>\n",
    "    <td>Padding, strides, transposed</td>\n",
    "    <td>Padding, strides, transposed (odd)</td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "## Dilated convolution animations\n",
    "\n",
    "_N.B.: Blue maps are inputs, and cyan maps are outputs._\n",
    "\n",
    "<table style=\"width:25%\"; table-layout:fixed;>\n",
    "  <tr>\n",
    "    <td><img width=\"150px\" src=\"img/gif/dilation.gif\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>No padding, no stride, dilation</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "*Источник: https://github.com/vdumoulin/conv_arithmetic*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Свертки в OpenCV (Фильтрация изображений)\n",
    "\n",
    "Как и в одномерных сигналах, изображения также могут быть отфильтрованы с помощью различных низкочастотных фильтров (LPF), высокочастотных фильтров (HPF) и т.д. \n",
    "**LPF** помогает удалять шумы, размывать изображения. Фильтры **HPF** помогают находить края в изображений.\n",
    "\n",
    "**OpenCV** предоставляет функцию **cv2.filter2D()** для объединения ядра с изображением. В качестве примера мы попробуем усредняющий фильтр на изображении. Ядро усредняющего фильтра $5\\times5$ будет выглядеть так:\n",
    "\n",
    "${\\begin{equation*}\n",
    "\\ K = \\frac{1}{25} \\begin{pmatrix}\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \n",
    "\\end{pmatrix}\n",
    "\\end{equation*}}$\n",
    "\n",
    "Свертка выполняется согласно теоретическим примерам выше. Как результат мы получаем осредненные пиксели своими 25 соседями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:48.901752Z",
     "start_time": "2020-09-14T17:47:48.889759Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('img/8_ka.jpg')\n",
    "# для отрисовки в pyplot\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:49.964684Z",
     "start_time": "2020-09-14T17:47:49.433616Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5), dtype=np.float32)\n",
    "kernel /= np.sum(kernel)\n",
    "dst = cv2.filter2D(img.copy(), -1, kernel)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(dst);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Фильтрация изображения**\n",
    "\n",
    "Размытие изображения достигается путем свертывания изображения с помощью фильтра нижних частот. Это полезно для удаления шумов. Это фактически удаляет высокочастотный контент (например: шум, края) с изображения. Таким образом, края в этой операции немного размыты. (Ну, есть методы размытия, которые тоже не размывают края). **OpenCV** предоставляет в основном четыре типа техники размытия.\n",
    "\n",
    "Более подробное описание реализации фильтров OpenCV есть в [документации](https://docs.opencv.org/3.4.2/d4/d86/group__imgproc__filter.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Усреднение\n",
    "Это делается путем свертки изображения с помощью нормализованного прямоугольного фильтра. Он просто берет среднее значение всех пикселей в области ядра и заменяет центральный элемент. Это выполняется функцией **cv2.blur()** или **cv2.boxFilter()**. Для более подробной информации о ядре посмотрите в документации. Мы должны указать ширину и высоту ядра. Нормализованный блочный фильтр $3\\times3$ будет выглядеть следующим образом:\n",
    "\n",
    "${\\begin{equation*}K = \\frac{1}{9} \n",
    "{\\begin{pmatrix}\n",
    "1 & \\ 1 & \\ 1 \\\\ \n",
    "1 & \\ 1 & \\ 1 \\\\ \n",
    "1 & \\ 1 & \\ 1 \\end{pmatrix}}\n",
    "\\end{equation*}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:51.430604Z",
     "start_time": "2020-09-14T17:47:50.905673Z"
    }
   },
   "outputs": [],
   "source": [
    "blur = cv2.blur(img.copy(), (3, 3))\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(blur);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Размытие по Гауссу\n",
    "При этом вместо box filter используется ядро Гаусса. Это делается с помощью функции **cv2.GaussianBlur()**. Мы должны указать ширину и высоту ядра, которые должны быть положительными и нечетными. Мы также должны указать стандартное отклонение в направлениях **X** и **Y**, **sigmaX** и **sigmaY** соответственно. Если указан только **sigmaX**, то **sigmaY** принимается так же, как **sigmaX**. Если оба даны в виде нулей, они рассчитываются по размеру ядра. Размытие по Гауссу очень эффективно для удаления гауссовского шума с изображения.\n",
    "\n",
    "Если вы хотите, вы можете создать ядро Гаусса с помощью функции **cv2.getGaussianKernel()**, а затем применить его с помощью **cv2.filter2D()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гауссово окно\n",
    "\n",
    "Гауссова функция (гауссиан, гауссиана, функция Гаусса) — вещественная функция, описываемая следующей формулой:\n",
    "\n",
    "${\\displaystyle g\\left(x\\right)=a*exp{-{\\frac {(x-b)^{2}}{2c^{2}}}}}$\n",
    "\n",
    "Эта функция имеет широкое приминение в математической статистике. В таком случае параметры выражаются через среднеквадратичное отклонение ${\\displaystyle \\sigma }$ и математическое ожидание ${\\displaystyle \\mu }$ :\n",
    "\n",
    "${\\displaystyle a={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}}, {\\displaystyle b=\\mu }, {\\displaystyle c=\\sigma }$\n",
    "\n",
    "В двумерном виде она имеет такое представление:\n",
    "\n",
    "${\\displaystyle g(x,y)=A\\cdot exp{\\left(-\\left({\\frac {(x-x_{0})^{2}}{2\\sigma _{x}^{2}}}+{\\frac {(y-y_{0})^{2}}{2\\sigma _{y}^{2}}}\\right)\\right)}}$\n",
    "\n",
    "Стандартным статистическим способом мы определили ширину гауссовой формы в терминах $\\sigma$. Тем не менее, когда для сглаживания используется гауссиан, для сканеров характерно описывать ширину гауссиана с помощью другой связанной меры - полной ширины на половине максимума (FWHM).\n",
    "\n",
    "FWHM - ширина ядра, равная половине максимума высоты гауссианы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:52.601399Z",
     "start_time": "2020-09-14T17:47:52.329618Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def fwhm2sigma(fwhm):\n",
    "    return fwhm / np.sqrt(8 * np.log(2))\n",
    "FWHM = 1\n",
    "sigma = fwhm2sigma(FWHM)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "dx = 0.1\n",
    "dy = 0.1\n",
    "x = np.arange(-6, 6, dx)\n",
    "y = np.arange(-6, 6, dy)\n",
    "x2d, y2d = np.meshgrid(x, y)\n",
    "kernel_2d = np.exp(-(x2d ** 2 + y2d ** 2) / (2 * sigma ** 2))\n",
    "kernel_2d = kernel_2d / (2 * np.pi * sigma ** 2) # unit integral\n",
    "ax.plot_surface(x2d, y2d, kernel_2d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, можно представить, что окно гаусса представляет из себя проекцию функции на плоскость. Проиллюстрировано на картинке:\n",
    "\n",
    "<img src=\"img/gaus_win.png\" alt=\"Drawing\" style=\"width: 300px;\"/> \n",
    "\n",
    "Собственно, теперь перейдем к __threshold__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:54.198443Z",
     "start_time": "2020-09-14T17:47:53.199200Z"
    }
   },
   "outputs": [],
   "source": [
    "## Код для размытия по Гауссу: \n",
    "\n",
    "blur1 = cv2.GaussianBlur(img.copy(), (9,9), 0)\n",
    "blur2 = cv2.GaussianBlur(img.copy(), (9,9), 2)\n",
    "blur3 = cv2.GaussianBlur(img.copy(), (9,9), 5)\n",
    "\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 4, figsize=(22, 8))\n",
    "ax1, ax2, ax3, ax4 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img)\n",
    "ax2.set_title(r'Результат свертки $\\sigma_X = \\sigma_Y = 0$')\n",
    "ax2.imshow(blur1)\n",
    "ax3.set_title(r'Результат свертки $\\sigma_X = \\sigma_Y = 2$')\n",
    "ax3.imshow(blur2)\n",
    "ax4.set_title(r'Результат свертки $\\sigma_X = \\sigma_Y = 5$')\n",
    "ax4.imshow(blur3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Среднее размытие\n",
    "Здесь функция **cv2.medianBlur()** принимает медиану всех пикселей в области ядра, и центральный элемент заменяется этим медианным значением. Это очень эффективно против шума соли и перца на изображениях. Интересно, что в вышеупомянутых фильтрах центральным элементом является вновь вычисленное значение, которое может быть значением пикселя в изображении или новым значением. Но при медианном размытии центральный элемент всегда заменяется некоторым пиксельным значением на изображении. \n",
    "\n",
    "Эффективно снижает шум. Размер его ядра должен быть положительным нечетным целым числом.\n",
    "\n",
    "В этой демонстрации я добавил шум к нашему исходному изображению и применил медианное размытие. Проверьте результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:47:58.855375Z",
     "start_time": "2020-09-14T17:47:58.321556Z"
    }
   },
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0, 2, size=noise_img.shape).astype(np.bool)\n",
    "r = np.random.rand(*noise_img.shape) * np.max(noise_img)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "median = cv2.medianBlur(noise_img, 7)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(noise_img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(median);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Двусторонняя фильтрация\n",
    "\n",
    "**cv2.bilateralFilter()** очень эффективно удаляет шум, сохраняя края острыми. Но операция медленнее по сравнению с другими фильтрами. Мы уже видели, что фильтр Гаусса берет окрестность вокруг пикселя и находит его средневзвешенное значение по Гауссу. Этот гауссов фильтр является функцией только одного пространства, то есть при фильтрации учитываются соседние пиксели. Он не учитывает, имеют ли пиксели почти одинаковую интенсивность. Он не учитывает, является ли пиксель краевым или нет. Таким образом, это стирает края, что мы не хотим делать.\n",
    "\n",
    "Двусторонний фильтр также принимает гауссов фильтр в пространстве, но еще один гауссов фильтр, который является функцией разности пикселей. Гауссова функция пространства обеспечивает размытие только соседних пикселей, а гауссова функция разности интенсивности - размытие только тех пикселей, интенсивность которых равна центральной. Таким образом, он сохраняет края, поскольку пиксели на краях будут сильно изменяться.\n",
    "\n",
    "**Рекомендации к фильтру:**\n",
    "\n",
    "* **Sigma values:** для простоты вы можете установить два значения сигмы одинаковыми. Если они маленькие ($<10$), фильтр не будет иметь большого эффекта, тогда как если они большие ($>150$), они будут иметь очень сильный эффект, делая изображение мультяшным.\n",
    "\n",
    "* **Размер фильтра:** Большие фильтры (d$>5$) очень медленные, поэтому рекомендуется использовать d $=5$ для приложений реального времени и, возможно, d $=9$ для автономных приложений, которые нуждаются в сильной фильтрации шума.\n",
    "\n",
    "Ниже приведены примеры использования двустороннего фильтра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:00.172590Z",
     "start_time": "2020-09-14T17:47:59.672792Z"
    }
   },
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0, 2, size=noise_img.shape).astype(np.bool)\n",
    "r = np.random.rand(*noise_img.shape) * np.max(noise_img)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "bilateral = cv2.bilateralFilter(noise_img, d=5, sigmaColor=150, sigmaSpace=250)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(noise_img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(bilateral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Элайзинг изображений\n",
    "\n",
    "Размытие по Гауссу обычно используется при уменьшении размера изображения. При понижающей дискретизации изображения обычно применяют фильтр низких частот к изображению перед повторной дискретизацией. Это делается для того, чтобы ложная высокочастотная информация не появлялась на изображении с пониженной дискретизацией (aliasing). Гауссовские размытия имеют хорошие свойства, такие как отсутствие острых краев. \n",
    "\n",
    "Проясним на примере:\n",
    "<table style=\"width:55%\"; table-layout:fixed;>\n",
    "  <tr>\n",
    "    <td><img src=\"img/alising_nan.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "    <td><img src=\"img/alising.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Изображение без сжатия</td>\n",
    "    <td>Эффект alising от сжатия</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Кросс-корреляция**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, есть два изображения, которые выглядят похожими, но слегка смещены. Мы можем оценить, насколько и в каком направлении смещены изображения, сравнивая их преобразования Фурье.\n",
    "\n",
    "<img src=\"img/shifted_spectrum.png\" alt=\"Drawing\" style=\"width: 500px;\"/> \n",
    "\n",
    "Эта техника может быть использована для стабилизации видео на уже снятых видео. Как только мы узнали, насколько сильно смещаются два последовательных кадра видео, мы можем искусственно сдвинуть второй кадр так, чтобы он больше не смещался."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV реализует совпадение шаблонов в функции matchTemplate. Доступные методы 6:\n",
    "\n",
    "**method=CV_TM_SQDIFF**\n",
    "\n",
    "$R(x,y)= \\sum _{x',y'} (T(x',y')-I(x+x',y+y'))^2$\n",
    "\n",
    "**method=CV_TM_SQDIFF_NORMED**\n",
    "\n",
    "$R(x,y)= \\frac{\\sum_{x',y'} (T(x',y')-I(x+x',y+y'))^2}{\\sqrt{\\sum_{x',y'}T(x',y')^2 \\cdot \\sum_{x',y'} I(x+x',y+y')^2}}$\n",
    "\n",
    "**method=CV_TM_CCORR**\n",
    "\n",
    "$R(x,y)= \\sum _{x',y'} (T(x',y')  \\cdot I(x+x',y+y'))$\n",
    "\n",
    "**method=CV_TM_CCORR_NORMED**\n",
    "\n",
    "$R(x,y)= \\frac{\\sum_{x',y'} (T(x',y') \\cdot I(x+x',y+y'))}{\\sqrt{\\sum_{x',y'}T(x',y')^2 \\cdot \\sum_{x',y'} I(x+x',y+y')^2}}$\n",
    "\n",
    "**method=CV_TM_CCOEFF**\n",
    "\n",
    "$R(x,y)= \\sum _{x',y'} (T'(x',y')  \\cdot I(x+x',y+y'))$\n",
    "\n",
    "где\n",
    "\n",
    "$\\begin{array}{l} T'(x',y')=T(x',y') - 1/(w  \\cdot h)  \\cdot \\sum _{x'',y''} T(x'',y'') \\\\ I'(x+x',y+y')=I(x+x',y+y') - 1/(w  \\cdot h)  \\cdot \\sum _{x'',y''} I(x+x'',y+y'') \\end{array}$\n",
    "\n",
    "**thod=CV_TM_CCOEFF_NORMED**\n",
    "\n",
    "$R(x,y)= \\frac{ \\sum_{x',y'} (T'(x',y') \\cdot I'(x+x',y+y')) }{ \\sqrt{\\sum_{x',y'}T'(x',y')^2 \\cdot \\sum_{x',y'} I'(x+x',y+y')^2} }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:02.438117Z",
     "start_time": "2020-09-14T17:48:02.225165Z"
    }
   },
   "outputs": [],
   "source": [
    "img_rgb = cv2.imread('img/mario_world.jpg')\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread('img/mario_coin.jpg', 0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.8\n",
    "loc = np.where( res >= threshold)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 3)\n",
    "    \n",
    "img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(6.4*3, 4.8*3), constrained_layout=False)\n",
    "plt.subplot(131), plt.imshow(img_gray, cmap='gray'), plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "plt.subplot(132), plt.imshow(template, cmap='gray'), plt.title(\"Template\")\n",
    "plt.axis('off')\n",
    "plt.subplot(133), plt.imshow(img_rgb), plt.title(\"Match result\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase correlation\n",
    "\n",
    "Использование преобразования Фурье не ограничивается фильтрацией. Если мы берем преобразование Фурье из двух последовательных кадров в видео, мы можем извлечь движение кадров. Это движение может быть использовано для коррекции дрожания камеры. Мы рассмотрим его фоновую математику и ее практическое применение в следующих постах. Этот алгоритм называется \"Фазовая корреляция\".\n",
    "\n",
    "<img src=\"img/phase_correlation.png\" alt=\"Drawing\" style=\"width: 600px;\"/> \n",
    "\n",
    "Алгоритм фазовой корреляции в основном заключается в том, чтобы просто взять преобразование Фурье двух изображений, а затем выполнить по ним некоторое вычисление.\n",
    "\n",
    "Сначала мы сделаем преобразование Фурье из двух изображений масштаба серого 1 и 2. Мы ожидаем, что эти изображения будут двумя последовательными кадрами в видео, снятом дрожащей камерой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:06.917562Z",
     "start_time": "2020-09-14T17:48:06.913572Z"
    }
   },
   "outputs": [],
   "source": [
    "image1_filename = 'img/img1.jpg'\n",
    "image2_filename = 'img/img2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:07.147428Z",
     "start_time": "2020-09-14T17:48:07.127364Z"
    }
   },
   "outputs": [],
   "source": [
    "image1 = cv2.imread(image1_filename, 0)\n",
    "image2 = cv2.imread(image2_filename, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:07.540943Z",
     "start_time": "2020-09-14T17:48:07.535963Z"
    }
   },
   "outputs": [],
   "source": [
    "image1.shape, image2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:08.030722Z",
     "start_time": "2020-09-14T17:48:07.979031Z"
    }
   },
   "outputs": [],
   "source": [
    "f1 = cv2.dft(image1.astype(np.float32),    \n",
    "              flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "f2 = cv2.dft(image2.astype(np.float32),   \n",
    "              flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "f1_shf = np.fft.fftshift(f1) \n",
    "f2_shf = np.fft.fftshift(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что все f1, f2, f1_shf и s2_shf имеют глубину = 2. Одна - для реальной части преобразования Фурье, а другая - для воображаемой. Поэтому мы должны объединить их до одного комплексного значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:08.875391Z",
     "start_time": "2020-09-14T17:48:08.840454Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_shf_cplx = f1_shf[:,:,0] + 1j*f1_shf[:,:,1]\n",
    "f2_shf_cplx = f2_shf[:,:,0] + 1j*f2_shf[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы запускаем алгоритм фазовой корреляции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:09.823430Z",
     "start_time": "2020-09-14T17:48:09.753558Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_shf_abs = np.abs(f1_shf_cplx)\n",
    "f2_shf_abs = np.abs(f2_shf_cplx)\n",
    "total_abs = f1_shf_abs * f2_shf_abs\n",
    "\n",
    "P_real = (np.real(f1_shf_cplx)*np.real(f2_shf_cplx) +\n",
    "          np.imag(f1_shf_cplx)*np.imag(f2_shf_cplx))/total_abs\n",
    "\n",
    "P_imag = (np.imag(f1_shf_cplx)*np.real(f2_shf_cplx) +\n",
    "          np.real(f1_shf_cplx)*np.imag(f2_shf_cplx))/total_abs\n",
    "P_complex = P_real + 1j*P_imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То, что мы здесь делаем, это получаем произведение двух комплексных чисел (на самом деле, это не одно значение, а скорее изображение). P_real - это реальная часть продукта, а P_imag - воображаемая часть. Обратите внимание, что они нормализуются путем деления на их размер.\n",
    "\n",
    "Наконец, мы применяем обратное преобразование Фурье к P_комплексу. В результате получается реальное изображение, почти черное, но имеющее только один сияющий белый пиксель. Расположение пикселя говорит о том, насколько сильно сместились два кадра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:48.756104Z",
     "start_time": "2020-09-14T17:48:48.345995Z"
    }
   },
   "outputs": [],
   "source": [
    "P_inverse = np.abs(np.fft.ifft2(P_complex)) # inverse FFT\n",
    "max_id = [0, 0]\n",
    "max_val = 0\n",
    "h, w = image1.shape\n",
    "for idy in range(h):\n",
    "    for idx in range(w):\n",
    "        if P_inverse[idy,idx] > max_val:\n",
    "            max_val = P_inverse[idy,idx]\n",
    "            max_id = [idy, idx]\n",
    "shift_x = h - max_id[0]\n",
    "shift_y = w - max_id[1]\n",
    "print(shift_x, shift_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы компенсируем сдвиг, основанный на этих предсказаниях. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T17:48:50.462414Z",
     "start_time": "2020-09-14T17:48:50.057859Z"
    }
   },
   "outputs": [],
   "source": [
    "image1_rgb = cv2.imread(image1_filename)\n",
    "image1_rgb = cv2.cvtColor(image1_rgb, cv2.COLOR_BGR2RGB)\n",
    "image2_rgb = cv2.imread(image2_filename)\n",
    "image2_rgb = cv2.cvtColor(image2_rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cv2.rectangle(image1_rgb, (0, 0), (image1_rgb.shape[0] - shift_x, image1_rgb.shape[1] - shift_y), (0, 255, 0), 10)\n",
    "cv2.rectangle(image2_rgb, (shift_x, shift_y), (image2_rgb.shape[0], image2_rgb.shape[1]), (0, 255, 0), 10)\n",
    "\n",
    "plt.figure(figsize=(6.4*2, 4.8*2), constrained_layout=False)\n",
    "plt.subplot(121), plt.imshow(image1_rgb), plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122), plt.imshow(image2_rgb), plt.title(\"Spectrum\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
